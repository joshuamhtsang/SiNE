{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real-Time Network Emulation Visualization\n",
    "\n",
    "This notebook provides real-time visualization of the running SiNE emulation.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "1. **Channel server must be running**: `uv run sine channel-server`\n",
    "2. **Emulation must be deployed**: `sudo $(which uv) run sine deploy <topology.yaml>`\n",
    "\n",
    "## How It Works\n",
    "\n",
    "- Polls the channel server's `/api/visualization/state` endpoint\n",
    "- Displays cached path data from previous channel computations\n",
    "- Shows wireless channel metrics (delay spread, K-factor, coherence bandwidth)\n",
    "- Updates every 1 second (configurable)\n",
    "\n",
    "**Important**: No computation is performed in this notebook - all data is pre-computed and cached by the channel server during emulation deployment/updates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Setup and Configuration\n",
    "import asyncio\n",
    "import httpx\n",
    "from IPython.display import clear_output, display\n",
    "from typing import Any\n",
    "\n",
    "# Configuration\n",
    "CHANNEL_API = \"http://localhost:8000\"\n",
    "UPDATE_INTERVAL_SEC = 1.0  # Poll interval\n",
    "MAX_RENDER_PATHS = 5       # Limit paths per link for performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Helper Functions\n",
    "async def fetch_visualization_state() -> dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Fetch complete visualization state from channel server.\n",
    "\n",
    "    Returns scene geometry, device positions, and CACHED paths.\n",
    "    No computation required - instant response.\n",
    "    \"\"\"\n",
    "    async with httpx.AsyncClient(timeout=5.0) as client:\n",
    "        response = await client.get(f\"{CHANNEL_API}/api/visualization/state\")\n",
    "        response.raise_for_status()\n",
    "        return response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Scene Preview with Paths (Option 2: Re-compute paths in notebook)\n",
    "from sionna.rt import load_scene, Transmitter, Receiver, PlanarArray, PathSolver\n",
    "import numpy as np\n",
    "from typing import Optional\n",
    "from pathlib import Path\n",
    "\n",
    "def render_scene_with_paths(viz_state: dict[str, Any], clip_at: Optional[float] = None) -> None:\n",
    "    \"\"\"\n",
    "    Render 3D scene with devices and propagation paths using Sionna preview.\n",
    "    \n",
    "    Implementation: Option 2 (Re-compute paths for visualization)\n",
    "    - Uses cached device positions from channel server\n",
    "    - Re-runs PathSolver in notebook to get Paths object\n",
    "    - Small overhead acceptable for snapshot/infrequent visualization\n",
    "    \n",
    "    Args:\n",
    "        viz_state: Visualization state from channel server\n",
    "        clip_at: Optional z-coordinate to clip scene (useful for indoor scenes)\n",
    "    \"\"\"\n",
    "    scene_file = viz_state.get('scene_file')\n",
    "    if not scene_file:\n",
    "        print(\"No scene file available - text visualization only\")\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        # Resolve scene path - handle both absolute and relative paths\n",
    "        scene_path = Path(scene_file)\n",
    "        if not scene_path.is_absolute():\n",
    "            notebook_dir = Path.cwd()\n",
    "            if notebook_dir.name == 'scenes':\n",
    "                project_root = notebook_dir.parent\n",
    "            else:\n",
    "                project_root = notebook_dir\n",
    "            scene_path = project_root / scene_file\n",
    "        \n",
    "        if not scene_path.exists():\n",
    "            print(f\"Scene file not found: {scene_path}\")\n",
    "            print(f\"Current directory: {Path.cwd()}\")\n",
    "            print(\"Continuing with text-only visualization...\")\n",
    "            return\n",
    "        \n",
    "        # Load scene (merge_shapes=False to keep surfaces separate)\n",
    "        scene = load_scene(str(scene_path), merge_shapes=False)\n",
    "        \n",
    "        # Configure minimal antenna arrays for visualization\n",
    "        scene.tx_array = PlanarArray(\n",
    "            num_rows=1, num_cols=1,\n",
    "            vertical_spacing=0.5, horizontal_spacing=0.5,\n",
    "            pattern=\"iso\", polarization=\"V\"\n",
    "        )\n",
    "        scene.rx_array = PlanarArray(\n",
    "            num_rows=1, num_cols=1,\n",
    "            vertical_spacing=0.5, horizontal_spacing=0.5,\n",
    "            pattern=\"iso\", polarization=\"V\"\n",
    "        )\n",
    "        \n",
    "        # Set frequency (important for material properties)\n",
    "        scene.frequency = 5.18e9  # 5.18 GHz (WiFi 5)\n",
    "        \n",
    "        # Add devices from cached positions\n",
    "        tx_added = set()\n",
    "        rx_added = set()\n",
    "        \n",
    "        for link in viz_state[\"paths\"]:\n",
    "            tx_name = link[\"tx_name\"]\n",
    "            rx_name = link[\"rx_name\"]\n",
    "            tx_pos = link[\"tx_position\"]\n",
    "            rx_pos = link[\"rx_position\"]\n",
    "            \n",
    "            # Add TX if not already added\n",
    "            if tx_name not in tx_added:\n",
    "                scene.add(Transmitter(name=tx_name, position=tx_pos))\n",
    "                tx_added.add(tx_name)\n",
    "            \n",
    "            # Add RX if not already added\n",
    "            if rx_name not in rx_added:\n",
    "                scene.add(Receiver(name=rx_name, position=rx_pos))\n",
    "                rx_added.add(rx_name)\n",
    "        \n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(\"3D SCENE PREVIEW WITH PROPAGATION PATHS\")\n",
    "        print(f\"{'='*70}\")\n",
    "        print(f\"Scene: {scene_path}\")\n",
    "        print(f\"Devices: {len(tx_added)} TX, {len(rx_added)} RX\")\n",
    "        print(f\"Links: {len(viz_state['paths'])}\")\n",
    "        print(\"\\nComputing propagation paths for visualization...\")\n",
    "        print(\"(Note: Paths are re-computed from cached positions)\")\n",
    "        \n",
    "        # Re-compute paths using PathSolver\n",
    "        # This is redundant (already computed for netem), but necessary\n",
    "        # to get a Sionna Paths object for scene.preview()\n",
    "        solver = PathSolver()\n",
    "        paths = solver(scene)\n",
    "        \n",
    "        print(\"Paths computed successfully!\")\n",
    "        print(f\"{'='*70}\\n\")\n",
    "        \n",
    "        # Preview scene with paths and clipping\n",
    "        if clip_at is not None:\n",
    "            scene.preview(paths=paths, clip_at=clip_at)\n",
    "        else:\n",
    "            scene.preview(paths=paths)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Failed to render scene: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        print(f\"Scene path attempted: {scene_path if 'scene_path' in locals() else scene_file}\")\n",
    "        print(f\"Current directory: {Path.cwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Text Display with Wireless Metrics\n",
    "def display_text_summary(viz_state: dict[str, Any]) -> None:\n",
    "    \"\"\"\n",
    "    Display text summary of visualization state with wireless channel analysis.\n",
    "    \n",
    "    Args:\n",
    "        viz_state: Visualization state from channel server\n",
    "    \"\"\"\n",
    "    print(f\"=== Visualization State (Cache: {viz_state['cache_size']} links) ===\")\n",
    "    print(f\"Scene: {viz_state.get('scene_file', 'N/A')}\\n\")\n",
    "\n",
    "    # Display device positions\n",
    "    print(\"Devices:\")\n",
    "    for device in viz_state[\"devices\"]:\n",
    "        pos = device[\"position\"]\n",
    "        print(f\"  {device['name']}: ({pos['x']:.1f}, {pos['y']:.1f}, {pos['z']:.1f})\")\n",
    "\n",
    "    # Display detailed channel information\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"WIRELESS CHANNEL ANALYSIS\")\n",
    "    print(f\"{'='*70}\")\n",
    "\n",
    "    for link_data in viz_state[\"paths\"]:\n",
    "        print(f\"\\nLink: {link_data['tx_name']} → {link_data['rx_name']}\")\n",
    "        print(f\"{'-'*70}\")\n",
    "\n",
    "        # Basic link info\n",
    "        print(f\"Distance: {link_data['distance_m']:.1f} m\")\n",
    "        print(f\"Paths: {link_data['num_paths_shown']}/{link_data['num_paths_total']} \"\n",
    "              f\"({link_data.get('power_coverage_percent', 100):.1f}% power)\")\n",
    "\n",
    "        # Delay spread analysis (ISI characterization)\n",
    "        rms_ds_ns = link_data.get('rms_delay_spread_ns', 0)\n",
    "        bc_mhz = link_data.get('coherence_bandwidth_hz', 0) / 1e6\n",
    "\n",
    "        print(f\"\\nDelay Characteristics:\")\n",
    "        print(f\"  RMS Delay Spread (τ_rms): {rms_ds_ns:.2f} ns\")\n",
    "        print(f\"  Coherence Bandwidth (Bc): {bc_mhz:.1f} MHz\")\n",
    "\n",
    "        # Frequency selectivity assessment\n",
    "        # Assume 80 MHz signal BW (adjust based on your config)\n",
    "        signal_bw_mhz = 80  # TODO: Get from link config\n",
    "        if bc_mhz > signal_bw_mhz:\n",
    "            print(f\"  ✓ Frequency-flat channel (Bc > BW)\")\n",
    "        else:\n",
    "            print(f\"  ⚠ Frequency-selective channel (Bc ≈ BW)\")\n",
    "            print(f\"    ISI may be significant - OFDM recommended\")\n",
    "\n",
    "        # LOS/NLOS classification via Rician K-factor\n",
    "        k_factor = link_data.get('k_factor_db')\n",
    "        dominant_type = link_data.get('dominant_path_type', 'unknown')\n",
    "\n",
    "        print(f\"\\nChannel Classification:\")\n",
    "        if k_factor is not None:\n",
    "            print(f\"  Rician K-factor: {k_factor:.1f} dB\")\n",
    "            if k_factor > 10:\n",
    "                print(f\"  → Strong LOS component (K > 10 dB)\")\n",
    "            elif k_factor > 0:\n",
    "                print(f\"  → Moderate LOS with multipath (0 < K < 10 dB)\")\n",
    "            else:\n",
    "                print(f\"  → NLOS dominant (K < 0 dB)\")\n",
    "        else:\n",
    "            print(f\"  Channel Type: NLOS (no direct path)\")\n",
    "            print(f\"  Dominant: {dominant_type}\")\n",
    "\n",
    "        # Individual path details\n",
    "        print(f\"\\nPropagation Paths (strongest {link_data['num_paths_shown']}):\")\n",
    "        for i, path in enumerate(link_data['paths'], 1):\n",
    "            los_marker = \" [LOS]\" if path['is_los'] else \"\"\n",
    "            interactions = \", \".join(path['interaction_types']) if path['interaction_types'] else \"direct\"\n",
    "            doppler = f\", Doppler: {path.get('doppler_hz', 0):.1f} Hz\" if path.get('doppler_hz') is not None else \"\"\n",
    "\n",
    "            print(f\"  Path {i}: {path['delay_ns']:.2f} ns, {path['power_db']:.1f} dB{los_marker}\")\n",
    "            print(f\"          Interactions: {interactions}{doppler}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: One-Time Snapshot with 3D Preview\n",
    "async def render_snapshot(show_3d: bool = True, clip_at: Optional[float] = 2.0) -> None:\n",
    "    \"\"\"\n",
    "    Render a single snapshot of current visualization state.\n",
    "    \n",
    "    Args:\n",
    "        show_3d: Whether to show 3D scene preview (default: True)\n",
    "        clip_at: Z-coordinate to clip scene at (default: 2.0m for indoor scenes)\n",
    "    \n",
    "    Use this instead of the continuous loop if you just want\n",
    "    to see the current state once.\n",
    "    \"\"\"\n",
    "    # Fetch current state\n",
    "    viz_state = await fetch_visualization_state()\n",
    "\n",
    "    # Display 3D scene preview if requested\n",
    "    if show_3d:\n",
    "        render_scene_with_paths(viz_state, clip_at=clip_at)\n",
    "    \n",
    "    # Display text summary\n",
    "    display_text_summary(viz_state)\n",
    "\n",
    "# Run snapshot (with 3D preview clipped at 2m height)\n",
    "await render_snapshot(show_3d=True, clip_at=2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Simple Scene Test with Paths (Diagnose preview issues)\n",
    "from sionna.rt import load_scene, Transmitter, Receiver, PlanarArray, PathSolver\n",
    "from pathlib import Path\n",
    "\n",
    "# Simple test: load scene, add devices, compute paths, and preview\n",
    "scene_path = Path(\"/home/joshua/Documents/SiNE/scenes/two_rooms.xml\")\n",
    "\n",
    "print(f\"Loading scene from: {scene_path}\")\n",
    "print(f\"File exists: {scene_path.exists()}\")\n",
    "\n",
    "scene = load_scene(str(scene_path), merge_shapes=False)\n",
    "print(f\"Scene loaded successfully with {len(scene.objects)} objects\")\n",
    "\n",
    "# Configure arrays\n",
    "scene.tx_array = PlanarArray(num_rows=1, num_cols=1, pattern=\"iso\", polarization=\"V\")\n",
    "scene.rx_array = PlanarArray(num_rows=1, num_cols=1, pattern=\"iso\", polarization=\"V\")\n",
    "scene.frequency = 5.18e9  # 5.18 GHz (WiFi 5)\n",
    "\n",
    "# Add TX in Room 1 and RX in Room 2 (matching two_rooms example positions)\n",
    "scene.add(Transmitter(name=\"tx1\", position=[10.0, 10.0, 1.0]))\n",
    "scene.add(Receiver(name=\"rx1\", position=[30.0, 10.0, 1.0]))\n",
    "\n",
    "print(\"\\nComputing propagation paths...\")\n",
    "# Compute paths using PathSolver (required to visualize paths)\n",
    "solver = PathSolver()\n",
    "paths = solver(scene)\n",
    "\n",
    "print(f\"Paths computed successfully!\")\n",
    "print(f\"\\nCalling scene.preview(paths=paths, clip_at=2.0)...\")\n",
    "print(\"Note: If you don't see a 3D viewer, your Jupyter environment may not support interactive preview.\")\n",
    "print(\"Try running this notebook in standard Jupyter Notebook (not VS Code) if the preview doesn't appear.\")\n",
    "print(\"\\nExpected: You should see propagation paths (lines) between the green TX and blue RX devices.\")\n",
    "\n",
    "# This should trigger the preview WITH PATHS visible\n",
    "scene.preview(paths=paths, clip_at=2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Create Animation Movie from Scene Rendering\n",
    "import asyncio\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from IPython.display import HTML, display\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sionna.rt import load_scene, Transmitter, Receiver, PlanarArray, PathSolver, Camera\n",
    "from typing import Any, List\n",
    "import io\n",
    "\n",
    "async def create_channel_movie(\n",
    "    t_monitor: float = 30.0,\n",
    "    delta_t: float = 1.0,\n",
    "    clip_at: float = 2.0,\n",
    "    resolution: tuple[int, int] = (800, 600),\n",
    "    num_samples: int = 32,\n",
    "    camera_position: tuple[float, float, float] = (40.0, 40.0, 45.0),\n",
    "    camera_look_at: tuple[float, float, float] = (20.0, 20.0, 0.0),\n",
    "    fov: float = 70.0\n",
    ") -> HTML:\n",
    "    \"\"\"\n",
    "    Create an animation movie of channel state over the past t_monitor seconds.\n",
    "    \n",
    "    This function:\n",
    "    1. Polls the channel server at delta_t intervals for t_monitor seconds\n",
    "    2. Renders the 3D scene with devices and paths at each time step using scene.render()\n",
    "    3. Saves rendered images to memory\n",
    "    4. Creates a playable matplotlib animation\n",
    "    \n",
    "    Args:\n",
    "        t_monitor: Total monitoring duration in seconds (default: 30s)\n",
    "        delta_t: Time interval between frames in seconds (default: 1s)\n",
    "        clip_at: Z-coordinate to clip scene at (default: 2.0m)\n",
    "        resolution: Image resolution as (width, height) (default: 800x600)\n",
    "        num_samples: Number of rendering samples for quality (default: 32, lower=faster)\n",
    "        camera_position: Camera position (x, y, z) in meters (default: 20, 20, 15)\n",
    "        camera_look_at: Point to look at (x, y, z) in meters (default: 20, 20, 0)\n",
    "        fov: Field of view in degrees (default: 45)\n",
    "    \n",
    "    Returns:\n",
    "        HTML video player widget for Jupyter\n",
    "    \n",
    "    Example:\n",
    "        # Create 30-second movie with 1-second intervals (30 frames)\n",
    "        movie = await create_channel_movie(t_monitor=30.0, delta_t=1.0)\n",
    "        \n",
    "        # Create 60-second movie with 2-second intervals (30 frames)\n",
    "        movie = await create_channel_movie(t_monitor=60.0, delta_t=2.0)\n",
    "        \n",
    "        # Fast rendering (lower quality, faster capture)\n",
    "        movie = await create_channel_movie(t_monitor=30.0, delta_t=1.0, num_samples=16)\n",
    "    \"\"\"\n",
    "    \n",
    "    num_frames = int(t_monitor / delta_t)\n",
    "    frames = []\n",
    "    timestamps = []\n",
    "    \n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"CREATING CHANNEL ANIMATION MOVIE\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"Monitoring duration: {t_monitor}s\")\n",
    "    print(f\"Frame interval: {delta_t}s\")\n",
    "    print(f\"Total frames: {num_frames}\")\n",
    "    print(f\"Resolution: {resolution[0]}x{resolution[1]}\")\n",
    "    print(f\"Render quality: {num_samples} samples (lower=faster)\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "    \n",
    "    # Pre-fetch scene info\n",
    "    print(\"Fetching initial scene configuration...\")\n",
    "    initial_state = await fetch_visualization_state()\n",
    "    scene_file = initial_state.get('scene_file')\n",
    "    \n",
    "    if not scene_file:\n",
    "        print(\"ERROR: No scene file available for rendering\")\n",
    "        return None\n",
    "    \n",
    "    # Resolve scene path\n",
    "    scene_path = Path(scene_file)\n",
    "    if not scene_path.is_absolute():\n",
    "        notebook_dir = Path.cwd()\n",
    "        if notebook_dir.name == 'scenes':\n",
    "            project_root = notebook_dir.parent\n",
    "        else:\n",
    "            project_root = notebook_dir\n",
    "        scene_path = project_root / scene_file\n",
    "    \n",
    "    if not scene_path.exists():\n",
    "        print(f\"ERROR: Scene file not found: {scene_path}\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"Scene file: {scene_path}\")\n",
    "    \n",
    "    # Create camera object\n",
    "    camera = Camera(position=camera_position, look_at=camera_look_at)\n",
    "    \n",
    "    print(f\"\\nStarting frame capture (this will take ~{t_monitor}s + rendering time)...\")\n",
    "    print(f\"Estimated total time: ~{t_monitor + num_frames * num_samples * 0.05:.1f}s\")\n",
    "    print(\"Progress: \", end='', flush=True)\n",
    "    \n",
    "    # Capture frames over monitoring period\n",
    "    for i in range(num_frames):\n",
    "        # Fetch current visualization state\n",
    "        try:\n",
    "            viz_state = await fetch_visualization_state()\n",
    "        except Exception as e:\n",
    "            print(f\"\\nWarning: Failed to fetch state at frame {i}: {e}\")\n",
    "            continue\n",
    "        \n",
    "        # Render scene to image\n",
    "        try:\n",
    "            frame_img = render_scene_frame(\n",
    "                viz_state=viz_state,\n",
    "                scene_path=scene_path,\n",
    "                camera=camera,\n",
    "                clip_at=clip_at,\n",
    "                resolution=resolution,\n",
    "                num_samples=num_samples,\n",
    "                fov=fov\n",
    "            )\n",
    "            \n",
    "            frames.append(frame_img)\n",
    "            timestamps.append(i * delta_t)\n",
    "            print('█', end='', flush=True)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"\\nWarning: Failed to render frame {i}: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            continue\n",
    "        \n",
    "        # Wait for next frame (except on last iteration)\n",
    "        if i < num_frames - 1:\n",
    "            await asyncio.sleep(delta_t)\n",
    "    \n",
    "    print(f\"\\n\\nCapture complete! Captured {len(frames)} frames\")\n",
    "    \n",
    "    if len(frames) == 0:\n",
    "        print(\"ERROR: No frames captured\")\n",
    "        return None\n",
    "    \n",
    "    # Create matplotlib animation\n",
    "    print(\"\\nCreating animation...\")\n",
    "    fig, ax = plt.subplots(figsize=(10, 7.5))\n",
    "    ax.axis('off')\n",
    "    \n",
    "    # Initialize with first frame\n",
    "    im = ax.imshow(frames[0])\n",
    "    time_text = ax.text(0.02, 0.98, '', transform=ax.transAxes,\n",
    "                        fontsize=16, color='white', verticalalignment='top',\n",
    "                        bbox=dict(boxstyle='round', facecolor='black', alpha=0.8))\n",
    "    \n",
    "    def update_frame(frame_idx):\n",
    "        \"\"\"Update function for animation\"\"\"\n",
    "        im.set_array(frames[frame_idx])\n",
    "        time_text.set_text(f'Time: {timestamps[frame_idx]:.1f}s / {t_monitor:.1f}s')\n",
    "        return [im, time_text]\n",
    "    \n",
    "    # Create animation\n",
    "    anim = FuncAnimation(\n",
    "        fig, \n",
    "        update_frame, \n",
    "        frames=len(frames),\n",
    "        interval=delta_t * 1000,  # Convert to milliseconds\n",
    "        blit=True,\n",
    "        repeat=True\n",
    "    )\n",
    "    \n",
    "    plt.close(fig)  # Don't display static figure\n",
    "    \n",
    "    print(\"Animation created successfully!\")\n",
    "    print(f\"\\nPlayback info:\")\n",
    "    print(f\"  - Frames: {len(frames)}\")\n",
    "    print(f\"  - Duration: {t_monitor}s\")\n",
    "    print(f\"  - Frame rate: {1/delta_t:.1f} fps\")\n",
    "    print(f\"  - Loop: Enabled\")\n",
    "    print(f\"\\nDisplaying movie player...\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "    \n",
    "    # Return HTML5 video widget\n",
    "    return HTML(anim.to_html5_video())\n",
    "\n",
    "\n",
    "def render_scene_frame(\n",
    "    viz_state: dict[str, Any],\n",
    "    scene_path: Path,\n",
    "    camera: Camera,\n",
    "    clip_at: float,\n",
    "    resolution: tuple[int, int],\n",
    "    num_samples: int,\n",
    "    fov: float\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Render a single frame using Sionna's scene.render() method.\n",
    "    \n",
    "    Args:\n",
    "        viz_state: Visualization state from channel server\n",
    "        scene_path: Path to scene XML file\n",
    "        camera: Camera object\n",
    "        clip_at: Clipping plane z-coordinate\n",
    "        resolution: (width, height) tuple\n",
    "        num_samples: Number of rendering samples\n",
    "        fov: Field of view in degrees\n",
    "    \n",
    "    Returns:\n",
    "        RGB image as numpy array (H, W, 3) with values in [0, 255]\n",
    "    \"\"\"\n",
    "    # Load scene\n",
    "    scene = load_scene(str(scene_path), merge_shapes=False)\n",
    "    \n",
    "    # Configure antenna arrays\n",
    "    scene.tx_array = PlanarArray(\n",
    "        num_rows=1, num_cols=1,\n",
    "        vertical_spacing=0.5, horizontal_spacing=0.5,\n",
    "        pattern=\"iso\", polarization=\"V\"\n",
    "    )\n",
    "    scene.rx_array = PlanarArray(\n",
    "        num_rows=1, num_cols=1,\n",
    "        vertical_spacing=0.5, horizontal_spacing=0.5,\n",
    "        pattern=\"iso\", polarization=\"V\"\n",
    "    )\n",
    "    scene.frequency = 5.18e9\n",
    "    \n",
    "    # Add devices from visualization state\n",
    "    tx_added = set()\n",
    "    rx_added = set()\n",
    "    \n",
    "    for link in viz_state[\"paths\"]:\n",
    "        tx_name = link[\"tx_name\"]\n",
    "        rx_name = link[\"rx_name\"]\n",
    "        tx_pos = link[\"tx_position\"]\n",
    "        rx_pos = link[\"rx_position\"]\n",
    "        \n",
    "        if tx_name not in tx_added:\n",
    "            scene.add(Transmitter(name=tx_name, position=tx_pos))\n",
    "            tx_added.add(tx_name)\n",
    "        \n",
    "        if rx_name not in rx_added:\n",
    "            scene.add(Receiver(name=rx_name, position=rx_pos))\n",
    "            rx_added.add(rx_name)\n",
    "    \n",
    "    # Compute paths\n",
    "    solver = PathSolver()\n",
    "    paths = solver(scene)\n",
    "    \n",
    "    # Render using scene.render() - pass camera object directly\n",
    "    # scene.render() accepts Camera object or string name\n",
    "    fig = scene.render(\n",
    "        camera=camera,\n",
    "        paths=paths,\n",
    "        clip_at=clip_at,\n",
    "        resolution=resolution,\n",
    "        num_samples=num_samples,\n",
    "        fov=fov,\n",
    "        show_devices=True,\n",
    "        return_bitmap=False  # Returns matplotlib Figure\n",
    "    )\n",
    "    \n",
    "    # Extract image from matplotlib figure\n",
    "    # Convert figure canvas to numpy array (modern matplotlib API)\n",
    "    fig.canvas.draw()\n",
    "    \n",
    "    # Get the RGBA buffer from the figure (modern API)\n",
    "    width, height = fig.canvas.get_width_height()\n",
    "    buf = np.frombuffer(fig.canvas.buffer_rgba(), dtype=np.uint8)\n",
    "    buf = buf.reshape((height, width, 4))\n",
    "    \n",
    "    # Convert RGBA to RGB (drop alpha channel)\n",
    "    buf = buf[:, :, :3]\n",
    "    \n",
    "    plt.close(fig)  # Clean up figure\n",
    "    \n",
    "    return buf\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "# Create a 30-second movie with 1-second intervals\n",
    "# movie = await create_channel_movie(t_monitor=30.0, delta_t=1.0)\n",
    "# display(movie)\n",
    "\n",
    "# Or create a 60-second movie with 2-second intervals (faster rendering)\n",
    "# movie = await create_channel_movie(t_monitor=60.0, delta_t=2.0, num_samples=16)\n",
    "# display(movie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Run Movie Creation\n",
    "# Create a 30-second movie with 1-second intervals\n",
    "# Adjust parameters as needed for your use case\n",
    "\n",
    "movie = await create_channel_movie(\n",
    "    t_monitor=30.0,      # Monitor for 30 seconds\n",
    "    delta_t=1.0,         # Capture frame every 1 second\n",
    "    clip_at=2.0,         # Clip scene at z=2.0m (for indoor scenes)\n",
    "    num_samples=16,      # Lower samples = faster rendering (16 is good for preview)\n",
    "    resolution=(800, 600)  # Image resolution\n",
    ")\n",
    "\n",
    "# Display the movie player\n",
    "display(movie)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sine",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
