{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real-Time Network Emulation Visualization\n",
    "\n",
    "This notebook provides real-time visualization of the running SiNE emulation.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "1. **Channel server must be running**: `uv run sine channel-server`\n",
    "2. **Emulation must be deployed**: `sudo $(which uv) run sine deploy <topology.yaml>`\n",
    "\n",
    "## How It Works\n",
    "\n",
    "- Polls the channel server's `/api/visualization/state` endpoint\n",
    "- Displays cached path data from previous channel computations\n",
    "- Shows wireless channel metrics (delay spread, K-factor, coherence bandwidth)\n",
    "- Updates every 1 second (configurable)\n",
    "\n",
    "**Important**: No computation is performed in this notebook - all data is pre-computed and cached by the channel server during emulation deployment/updates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Setup and Configuration\n",
    "import asyncio\n",
    "import httpx\n",
    "from IPython.display import clear_output, display\n",
    "from typing import Any\n",
    "\n",
    "# Configuration\n",
    "CHANNEL_API = \"http://localhost:8000\"\n",
    "UPDATE_INTERVAL_SEC = 1.0  # Poll interval\n",
    "MAX_RENDER_PATHS = 5       # Limit paths per link for performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Helper Functions\n",
    "async def fetch_visualization_state() -> dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Fetch complete visualization state from channel server.\n",
    "\n",
    "    Returns scene geometry, device positions, and CACHED paths.\n",
    "    No computation required - instant response.\n",
    "    \"\"\"\n",
    "    async with httpx.AsyncClient(timeout=5.0) as client:\n",
    "        response = await client.get(f\"{CHANNEL_API}/api/visualization/state\")\n",
    "        response.raise_for_status()\n",
    "        return response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 3: Scene Preview with Paths (Option 2: Re-compute paths in notebook)\nfrom sionna.rt import load_scene, Transmitter, Receiver, PlanarArray, PathSolver\nimport numpy as np\nfrom typing import Optional\nfrom pathlib import Path\n\ndef render_scene_with_paths(viz_state: dict[str, Any], clip_at: Optional[float] = None) -> None:\n    \"\"\"\n    Render 3D scene with devices and propagation paths using Sionna preview.\n    \n    Implementation: Option 2 (Re-compute paths for visualization)\n    - Uses cached device positions from channel server\n    - Re-runs PathSolver in notebook to get Paths object\n    - Small overhead acceptable for snapshot/infrequent visualization\n    \n    Args:\n        viz_state: Visualization state from channel server\n        clip_at: Optional z-coordinate to clip scene (useful for indoor scenes)\n    \"\"\"\n    scene_file = viz_state.get('scene_file')\n    if not scene_file:\n        print(\"No scene file available - text visualization only\")\n        return\n    \n    try:\n        # Resolve scene path - handle both absolute and relative paths\n        scene_path = Path(scene_file)\n        if not scene_path.is_absolute():\n            notebook_dir = Path.cwd()\n            if notebook_dir.name == 'scenes':\n                project_root = notebook_dir.parent\n            else:\n                project_root = notebook_dir\n            scene_path = project_root / scene_file\n        \n        if not scene_path.exists():\n            print(f\"Scene file not found: {scene_path}\")\n            print(f\"Current directory: {Path.cwd()}\")\n            print(\"Continuing with text-only visualization...\")\n            return\n        \n        # Load scene (merge_shapes=False to keep surfaces separate)\n        scene = load_scene(str(scene_path), merge_shapes=False)\n        \n        # Configure minimal antenna arrays for visualization\n        scene.tx_array = PlanarArray(\n            num_rows=1, num_cols=1,\n            vertical_spacing=0.5, horizontal_spacing=0.5,\n            pattern=\"iso\", polarization=\"V\"\n        )\n        scene.rx_array = PlanarArray(\n            num_rows=1, num_cols=1,\n            vertical_spacing=0.5, horizontal_spacing=0.5,\n            pattern=\"iso\", polarization=\"V\"\n        )\n        \n        # Set frequency (important for material properties)\n        scene.frequency = 5.18e9  # 5.18 GHz (WiFi 5)\n        \n        # Add devices from cached positions\n        tx_added = set()\n        rx_added = set()\n        \n        for link in viz_state[\"paths\"]:\n            tx_name = link[\"tx_name\"]\n            rx_name = link[\"rx_name\"]\n            tx_pos = link[\"tx_position\"]\n            rx_pos = link[\"rx_position\"]\n            \n            # Add TX if not already added\n            if tx_name not in tx_added:\n                scene.add(Transmitter(name=tx_name, position=tx_pos))\n                tx_added.add(tx_name)\n            \n            # Add RX if not already added\n            if rx_name not in rx_added:\n                scene.add(Receiver(name=rx_name, position=rx_pos))\n                rx_added.add(rx_name)\n        \n        print(f\"\\n{'='*70}\")\n        print(\"3D SCENE PREVIEW WITH PROPAGATION PATHS\")\n        print(f\"{'='*70}\")\n        print(f\"Scene: {scene_path}\")\n        print(f\"Devices: {len(tx_added)} TX, {len(rx_added)} RX\")\n        print(f\"Links: {len(viz_state['paths'])}\")\n        print(\"\\nComputing propagation paths for visualization...\")\n        print(\"(Note: Paths are re-computed from cached positions)\")\n        \n        # Re-compute paths using PathSolver\n        # This is redundant (already computed for netem), but necessary\n        # to get a Sionna Paths object for scene.preview()\n        solver = PathSolver(scene=scene)\n        paths = solver()\n        \n        print(\"Paths computed successfully!\")\n        print(f\"{'='*70}\\n\")\n        \n        # Preview scene with paths and clipping\n        if clip_at is not None:\n            scene.preview(paths=paths, clip_at=clip_at)\n        else:\n            scene.preview(paths=paths)\n            \n    except Exception as e:\n        print(f\"Failed to render scene: {e}\")\n        import traceback\n        traceback.print_exc()\n        print(f\"Scene path attempted: {scene_path if 'scene_path' in locals() else scene_file}\")\n        print(f\"Current directory: {Path.cwd()}\")"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Text Display with Wireless Metrics\n",
    "def display_text_summary(viz_state: dict[str, Any]) -> None:\n",
    "    \"\"\"\n",
    "    Display text summary of visualization state with wireless channel analysis.\n",
    "    \n",
    "    Args:\n",
    "        viz_state: Visualization state from channel server\n",
    "    \"\"\"\n",
    "    print(f\"=== Visualization State (Cache: {viz_state['cache_size']} links) ===\")\n",
    "    print(f\"Scene: {viz_state.get('scene_file', 'N/A')}\\n\")\n",
    "\n",
    "    # Display device positions\n",
    "    print(\"Devices:\")\n",
    "    for device in viz_state[\"devices\"]:\n",
    "        pos = device[\"position\"]\n",
    "        print(f\"  {device['name']}: ({pos['x']:.1f}, {pos['y']:.1f}, {pos['z']:.1f})\")\n",
    "\n",
    "    # Display detailed channel information\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"WIRELESS CHANNEL ANALYSIS\")\n",
    "    print(f\"{'='*70}\")\n",
    "\n",
    "    for link_data in viz_state[\"paths\"]:\n",
    "        print(f\"\\nLink: {link_data['tx_name']} → {link_data['rx_name']}\")\n",
    "        print(f\"{'-'*70}\")\n",
    "\n",
    "        # Basic link info\n",
    "        print(f\"Distance: {link_data['distance_m']:.1f} m\")\n",
    "        print(f\"Paths: {link_data['num_paths_shown']}/{link_data['num_paths_total']} \"\n",
    "              f\"({link_data.get('power_coverage_percent', 100):.1f}% power)\")\n",
    "\n",
    "        # Delay spread analysis (ISI characterization)\n",
    "        rms_ds_ns = link_data.get('rms_delay_spread_ns', 0)\n",
    "        bc_mhz = link_data.get('coherence_bandwidth_hz', 0) / 1e6\n",
    "\n",
    "        print(f\"\\nDelay Characteristics:\")\n",
    "        print(f\"  RMS Delay Spread (τ_rms): {rms_ds_ns:.2f} ns\")\n",
    "        print(f\"  Coherence Bandwidth (Bc): {bc_mhz:.1f} MHz\")\n",
    "\n",
    "        # Frequency selectivity assessment\n",
    "        # Assume 80 MHz signal BW (adjust based on your config)\n",
    "        signal_bw_mhz = 80  # TODO: Get from link config\n",
    "        if bc_mhz > signal_bw_mhz:\n",
    "            print(f\"  ✓ Frequency-flat channel (Bc > BW)\")\n",
    "        else:\n",
    "            print(f\"  ⚠ Frequency-selective channel (Bc ≈ BW)\")\n",
    "            print(f\"    ISI may be significant - OFDM recommended\")\n",
    "\n",
    "        # LOS/NLOS classification via Rician K-factor\n",
    "        k_factor = link_data.get('k_factor_db')\n",
    "        dominant_type = link_data.get('dominant_path_type', 'unknown')\n",
    "\n",
    "        print(f\"\\nChannel Classification:\")\n",
    "        if k_factor is not None:\n",
    "            print(f\"  Rician K-factor: {k_factor:.1f} dB\")\n",
    "            if k_factor > 10:\n",
    "                print(f\"  → Strong LOS component (K > 10 dB)\")\n",
    "            elif k_factor > 0:\n",
    "                print(f\"  → Moderate LOS with multipath (0 < K < 10 dB)\")\n",
    "            else:\n",
    "                print(f\"  → NLOS dominant (K < 0 dB)\")\n",
    "        else:\n",
    "            print(f\"  Channel Type: NLOS (no direct path)\")\n",
    "            print(f\"  Dominant: {dominant_type}\")\n",
    "\n",
    "        # Individual path details\n",
    "        print(f\"\\nPropagation Paths (strongest {link_data['num_paths_shown']}):\")\n",
    "        for i, path in enumerate(link_data['paths'], 1):\n",
    "            los_marker = \" [LOS]\" if path['is_los'] else \"\"\n",
    "            interactions = \", \".join(path['interaction_types']) if path['interaction_types'] else \"direct\"\n",
    "            doppler = f\", Doppler: {path.get('doppler_hz', 0):.1f} Hz\" if path.get('doppler_hz') is not None else \"\"\n",
    "\n",
    "            print(f\"  Path {i}: {path['delay_ns']:.2f} ns, {path['power_db']:.1f} dB{los_marker}\")\n",
    "            print(f\"          Interactions: {interactions}{doppler}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[31m2026-01-06 17:00:23 WARN  [HDRFilm] Monochrome mode enabled, setting film output pixel format to 'luminance' (was rgb).\n",
      "\n",
      "======================================================================\n",
      "3D SCENE PREVIEW\n",
      "======================================================================\n",
      "Scene: /home/joshua/Documents/SiNE/scenes/two_rooms.xml\n",
      "Devices: 1 TX, 1 RX\n",
      "Links: 1\n",
      "\n",
      "Note: Path visualization shows cached propagation paths\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd263b3d88514de899d1df1c1253da6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Renderer(camera=PerspectiveCamera(aspect=1.31, children=(DirectionalLight(intensity=0.25, posit…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8febdb9d4ce846dc9d09ef388acc9558",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Label(value='Clipping plane', layout=Layout(flex='2 2 auto', width='auto')), Checkbox(value=Tru…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Visualization State (Cache: 1 links) ===\n",
      "Scene: scenes/two_rooms.xml\n",
      "\n",
      "Devices:\n",
      "  node1: (10.0, 10.0, 1.0)\n",
      "  node2: (30.0, 10.0, 1.0)\n",
      "\n",
      "======================================================================\n",
      "WIRELESS CHANNEL ANALYSIS\n",
      "======================================================================\n",
      "\n",
      "Link: node1 → node2\n",
      "----------------------------------------------------------------------\n",
      "Distance: 20.0 m\n",
      "Paths: 5/9 (92.4% power)\n",
      "\n",
      "Delay Characteristics:\n",
      "  RMS Delay Spread (τ_rms): 61.67 ns\n",
      "  Coherence Bandwidth (Bc): 3.2 MHz\n",
      "  ⚠ Frequency-selective channel (Bc ≈ BW)\n",
      "    ISI may be significant - OFDM recommended\n",
      "\n",
      "Channel Classification:\n",
      "  Channel Type: NLOS (no direct path)\n",
      "  Dominant: los\n",
      "\n",
      "Propagation Paths (strongest 5):\n",
      "  Path 1: 0.00 ns, -99.4 dB\n",
      "          Interactions: refraction, refraction\n",
      "  Path 2: 145.03 ns, -101.3 dB\n",
      "          Interactions: specular_reflection, specular_reflection, specular_reflection\n",
      "  Path 3: 0.33 ns, -104.2 dB\n",
      "          Interactions: refraction, specular_reflection, refraction\n",
      "  Path 4: 0.33 ns, -104.2 dB\n",
      "          Interactions: refraction, specular_reflection, refraction\n",
      "  Path 5: 1.32 ns, -109.3 dB\n",
      "          Interactions: refraction, specular_reflection, refraction\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: One-Time Snapshot with 3D Preview\n",
    "async def render_snapshot(show_3d: bool = True, clip_at: Optional[float] = 2.0) -> None:\n",
    "    \"\"\"\n",
    "    Render a single snapshot of current visualization state.\n",
    "    \n",
    "    Args:\n",
    "        show_3d: Whether to show 3D scene preview (default: True)\n",
    "        clip_at: Z-coordinate to clip scene at (default: 2.0m for indoor scenes)\n",
    "    \n",
    "    Use this instead of the continuous loop if you just want\n",
    "    to see the current state once.\n",
    "    \"\"\"\n",
    "    # Fetch current state\n",
    "    viz_state = await fetch_visualization_state()\n",
    "\n",
    "    # Display 3D scene preview if requested\n",
    "    if show_3d:\n",
    "        render_scene_with_paths(viz_state, clip_at=clip_at)\n",
    "    \n",
    "    # Display text summary\n",
    "    display_text_summary(viz_state)\n",
    "\n",
    "# Run snapshot (with 3D preview clipped at 2m height)\n",
    "await render_snapshot(show_3d=True, clip_at=2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading scene from: /home/joshua/Documents/SiNE/scenes/two_rooms.xml\n",
      "File exists: True\n",
      "\u001b[0m\u001b[31m2026-01-06 17:00:40 WARN  [HDRFilm] Monochrome mode enabled, setting film output pixel format to 'luminance' (was rgb).\n",
      "Scene loaded successfully with 11 objects\n",
      "\n",
      "Calling scene.preview(clip_at=2.0)...\n",
      "Note: If you don't see a 3D viewer, your Jupyter environment may not support interactive preview.\n",
      "Try running this notebook in standard Jupyter Notebook (not VS Code) if the preview doesn't appear.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c3e10ae63804710bb917e8afcb1d0b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Renderer(camera=PerspectiveCamera(aspect=1.31, children=(DirectionalLight(intensity=0.25, posit…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc19e05f6ec64c57a7fac7a5df83dcf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Label(value='Clipping plane', layout=Layout(flex='2 2 auto', width='auto')), Checkbox(value=Tru…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cell 5c: Simple Scene Test (Diagnose preview issues)\n",
    "from sionna.rt import load_scene, Transmitter, Receiver, PlanarArray\n",
    "from pathlib import Path\n",
    "\n",
    "# Simple test: just load and preview the scene\n",
    "scene_path = Path(\"/home/joshua/Documents/SiNE/scenes/two_rooms.xml\")\n",
    "\n",
    "print(f\"Loading scene from: {scene_path}\")\n",
    "print(f\"File exists: {scene_path.exists()}\")\n",
    "\n",
    "scene = load_scene(str(scene_path), merge_shapes=False)\n",
    "print(f\"Scene loaded successfully with {len(scene.objects)} objects\")\n",
    "\n",
    "# Configure arrays\n",
    "scene.tx_array = PlanarArray(num_rows=1, num_cols=1, pattern=\"iso\", polarization=\"V\")\n",
    "scene.rx_array = PlanarArray(num_rows=1, num_cols=1, pattern=\"iso\", polarization=\"V\")\n",
    "scene.frequency = 5.18e9\n",
    "\n",
    "# Add a simple TX and RX\n",
    "scene.add(Transmitter(name=\"tx1\", position=[10.0, 10.0, 1.0]))\n",
    "scene.add(Receiver(name=\"rx1\", position=[30.0, 10.0, 1.0]))\n",
    "\n",
    "print(\"\\nCalling scene.preview(clip_at=2.0)...\")\n",
    "print(\"Note: If you don't see a 3D viewer, your Jupyter environment may not support interactive preview.\")\n",
    "print(\"Try running this notebook in standard Jupyter Notebook (not VS Code) if the preview doesn't appear.\")\n",
    "\n",
    "# This should trigger the preview\n",
    "scene.preview(clip_at=2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 7: Continuous Auto-Refresh Loop (for mobility scenarios)\nimport asyncio\nfrom IPython.display import clear_output\n\nasync def continuous_monitoring(update_interval_sec: float = 1.0, max_iterations: int = 100) -> None:\n    \"\"\"\n    Continuously poll and display visualization state.\n    \n    Args:\n        update_interval_sec: How often to refresh (default: 1.0 seconds)\n        max_iterations: Maximum number of updates (default: 100, ~1.6 minutes at 1s interval)\n    \n    Use this for monitoring mobility scenarios where device positions change.\n    Press 'Interrupt Kernel' (■ button) to stop.\n    \"\"\"\n    print(f\"Starting continuous monitoring (updating every {update_interval_sec}s)\")\n    print(\"Press 'Interrupt Kernel' (■ button in toolbar) to stop\\n\")\n    \n    iteration = 0\n    try:\n        while iteration < max_iterations:\n            clear_output(wait=True)\n            \n            # Fetch and display current state\n            viz_state = await fetch_visualization_state()\n            \n            print(f\"=== Update {iteration + 1}/{max_iterations} ===\")\n            print(f\"Timestamp: {asyncio.get_event_loop().time():.1f}s since start\\n\")\n            \n            # Display text summary (scene.preview() doesn't auto-refresh well)\n            display_text_summary(viz_state)\n            \n            print(f\"\\n{'='*70}\")\n            print(f\"Next update in {update_interval_sec}s... (Ctrl+C or ■ to stop)\")\n            print(f\"{'='*70}\")\n            \n            iteration += 1\n            await asyncio.sleep(update_interval_sec)\n            \n    except KeyboardInterrupt:\n        print(\"\\n\\nMonitoring stopped by user\")\n    except Exception as e:\n        print(f\"\\n\\nMonitoring stopped due to error: {e}\")\n        import traceback\n        traceback.print_exc()\n\n# Example: Monitor for 60 seconds (60 updates at 1s interval)\n# Uncomment the line below to start continuous monitoring:\n# await continuous_monitoring(update_interval_sec=1.0, max_iterations=60)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}